# ============================================================================
# Phase 3.A: Pre-training Configuration (GAP 3 - Transfer Learning)
# ============================================================================
# Purpose: Pre-train 3D U-Net on AMOS 2022 dataset to learn anatomical
#          structures before fine-tuning on pathology detection.
#
# Dataset: AMOS 2022 (500 CT + 100 MRI scans with organ annotations)
#          15 organ classes available
#          Download: https://amos22.grand-challenge.org/
#
# Duration: ~3 days on 2x RTX 6000 GPUs
# ============================================================================

# Paths (AMOS 2022 dataset)
paths:
  # Meta CSV with train/val/test splits and pathology info
  meta_csv: "data/meta.csv"
  
  # Split files (JSON format, auto-generated by prepare_amos_dataset.py)
  train_split: "splits/amos_train_cases.txt"
  val_split: "splits/amos_val_cases.txt"
  
  # Output directory for pre-trained model
  models_dir: "models"

# AMOS 2022 organ classes (15 organs)
# Reference: https://arxiv.org/abs/2206.08023
# 
# Class mapping strategy: Train on ALL 15 organ classes to learn
# comprehensive anatomical context. Our pathology detection benefits from
# understanding normal anatomy (colon, appendix, aorta, pancreas, etc.)
#
# AMOS organ classes:
#   0: Background
#   1: Spleen
#   2: Right Kidney
#   3: Left Kidney
#   4: Gallbladder
#   5: Esophagus
#   6: Liver
#   7: Stomach
#   8: Aorta
#   9: IVC (Inferior Vena Cava)
#   10: Portal/Splenic Vein
#   11: Pancreas
#   12: Right Adrenal Gland
#   13: Left Adrenal Gland
#   14: Duodenum
#   15: Bladder
#
# Transfer learning rationale:
# - Model learns anatomical context (colon position, vessel anatomy, etc.)
# - Pre-training on 500 cases >> 54 rare pathology examples
# - Reduces overfitting on Classes 4-5 during Phase 3.B fine-tuning


# Model architecture (same as Phase 3.B for compatibility)
model:
  in_channels: 1
  out_channels: 16            # Background + 15 AMOS organ classes
  channels: [32, 64, 128, 256, 512]
  strides: [2, 2, 2, 2]
  dropout: 0.1

# Data augmentation (standard for pre-training)
# NOTE: Preprocessing (HU clipping, normalization, spacing) is hardcoded in
#       scripts/transforms_amos.py based on AMOS paper specifications.
#       These values control augmentation only.
aug:
  patch_size: [192, 192, 160]
  pos_neg_ratio: 3.0
  flip_prob: 0.5
  rotate90_prob: 0.5
  scale_intensity: 0.1
  shift_intensity: 0.1

# Training configuration
train:
  epochs: 100
  batch_size: 2
  num_workers: 16
  val_every: 5
  mixed_precision: true

# Optimizer
optimizer:
  lr: 3e-4
  weight_decay: 1e-5

# Loss function (balanced for pre-training)
loss:
  dice_ce:
    # No class weights for AMOS - it's fairly balanced across organ classes
    class_weights: null

# Hardware
hardware:
  gpus: 2
  strategy: "ddp"
  precision: "16-mixed"

# Logging
logging:
  wandb_project: "abdomen-segmentation"
  experiment_name: "phase3a_amos_pretrain"
  log_every_n_steps: 10

